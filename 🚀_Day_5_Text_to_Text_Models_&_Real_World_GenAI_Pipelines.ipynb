{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpyBAh009wgr",
        "outputId": "83b224a3-1f94-4f64-91e6-ea98cd8266e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers torch\n",
        "!pip install tiktoken\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Summarizer**"
      ],
      "metadata": {
        "id": "F1cur3h0__h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model Name                        | Description                                         |\n",
        "| --------------------------------- | --------------------------------------------------- |\n",
        "| `\"facebook/bart-large-cnn\"`       | High-quality summarizer trained on CNN/DailyMail    |\n",
        "| `\"google/flan-t5-small\"`          | Lightweight, instruction-tuned summarizer           |\n",
        "| `\"sshleifer/distilbart-cnn-12-6\"` | Faster, distilled version of BART for summarization |\n"
      ],
      "metadata": {
        "id": "PI971CoxCQo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUH0H3WN-uJS",
        "outputId": "9d05250d-f120-42dd-8694-7ab343f287ea"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Generative AI is a field of artificial intelligence that enables machines to generate content.\n",
        "It can produce text, images, music, code, and more. Generative AI is used in tools like ChatGPT,\n",
        "DALLÂ·E, and Midjourney. These models are trained on large datasets and generate human-like results.\n",
        "\"\"\"\n",
        "\n",
        "summary = summarizer(text, max_length=20, min_length=10, do_sample=False)\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxNhD0L5-3bi",
        "outputId": "f75dac14-d06b-4087-f875-0b8b82128ebe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI is a field of artificial intelligence that enables machines to generate content. It\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Classifier (Text-to-Label Output)**"
      ],
      "metadata": {
        "id": "KEVuefjQAGZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "text = \"I realy Love this product\"\n",
        "result= classifier(text)\n",
        "print(\"Sentiment: \", result[0]['label'])\n",
        "print(\"Score: \", result[0]['score'])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fl4bSNZAIvF",
        "outputId": "49244aea-3de0-4945-b53d-e57b75426ab1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment:  POSITIVE\n",
            "Score:  0.9998810291290283\n",
            "[{'label': 'POSITIVE', 'score': 0.9998810291290283}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question Answering (Extractive)**"
      ],
      "metadata": {
        "id": "xLUeC-dgA3S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline(\"question-answering\")\n",
        "\n",
        "context = \"\"\"\n",
        "The transformer model architecture was introduced in the paper \"Attention is All You Need\".\n",
        "It uses self-attention mechanisms instead of traditional RNNs to process sequences.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Who introduced the Transformer Model Architecture\"\n",
        "\n",
        "result = qa(question=question, context=context)\n",
        "print(\"Answer: \", result.get('answer'))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq_1QlPAA4wq",
        "outputId": "b9f51e2f-1b88-4192-e3bd-e46b08b9413e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  the paper \"Attention is All You Need\".\n",
            "{'score': 0.06695668399333954, 'start': 54, 'end': 92, 'answer': 'the paper \"Attention is All You Need\".'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.nvidia.com/en-us/glossary/generative-ai/'\n",
        "\n",
        "def fetch_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    text = soup.get_text()\n",
        "    return text\n",
        "\n",
        "text = fetch_text_from_url(url)\n",
        "words = text.split()\n",
        "prompt = ' '.join(words[500:700])\n",
        "\n",
        "\n",
        "def count_token(text, model=\"gpt-3.5-turbo\"):\n",
        "  encoding = tiktoken.encoding_for_model(model)\n",
        "  output = encoding.encode(text)\n",
        "  return len(output)\n",
        "print(prompt)\n",
        "print(count_token(prompt))\n",
        "\n",
        "if count_token(prompt) > 100:\n",
        "   summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "   summary = summarizer(prompt, max_length=20, min_length=10, do_sample=False)\n",
        "   print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxKzhR1eC0FA",
        "outputId": "cb65176c-1d9a-484c-bb36-edb762867873"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "streaming media performance Graphics Cards and GPUs Blackwell Architecture The engine of the new industrial revolution Hopper Architecture High performance, scalability, and security for every data center Ada Lovelace Architecture Performance and energy efficiency for endless possibilities GeForce Graphics Cards RTX graphics cards bring game-changing AI capabilities NVIDIA RTX PRO Accelerating professional AI, graphics, rendering and compute workloads Virtual GPU Virtual solutions for scalable, high-performance computing Laptops GeForce Laptops GPU-powered laptops for gamers and creators Studio Laptops High performance laptops purpose-built for creators NVIDIA RTX PRO Laptops Accelerate professional AI and visual computing from anywhere Networking Overview Accelerated networks for modern workloads DPUs and SuperNICs Software-defined hardware accelerators for networking, storage, and security Ethernet Ethernet performance, availability, and ease of use across a wide range of applications InfiniBand High-performance networking for super computers, AI, and cloud data centers Networking Software Networking software for optimized performance and scalability Network Acceleration IO subsystem for modern, GPU-accelerated data centers Professional Workstations Overview Accelerating professional AI, graphics, rendering, and compute workloads DGX Spark A Grace Blackwell AI Supercomputer on your desk DGX Station The ultimate desktop AI supercomputer powered by NVIDIA Grace Blackwell NVIDIA RTX PRO AI Workstations Accelerate innovation and productivity in AI\n",
            "262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': 'Black Blackwell Architecture The engine of the new industrial revolution Hopper Architecture High performance, scal'}]\n"
          ]
        }
      ]
    }
  ]
}